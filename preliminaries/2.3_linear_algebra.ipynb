{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "fe55b9f24d8452108871416900996aa93b6395251a5e4265f5d848b4a5f6394b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "Useful formula :\n",
    "- $ B = A^T $ then $ a_{i, j} = b_{j, i} $\n",
    "- $ A $ is symmetric if $ A = A^T $\n",
    "- $ A + B = B + A $ "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Question 1 : Prove that the transpose of a matrix  $ A $’s transpose is  A :  $ (A^⊤)^⊤=A $.**\n",
    "\n",
    "let $ B = A^T $\n",
    "\n",
    "then $ b_{i, j} = a_{j, i} $\n",
    "\n",
    "let $ C = B^T $\n",
    "\n",
    "then $ c_{j, i} = b_{i, j} $\n",
    "\n",
    "\n",
    "$ c_{j, i} = a_{j, i} $\n",
    "so $ (A^T)^T = A $\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Question 2 : Given two matrices $ A $ and $ B $, show that the sum of transposes is equal to the transpose of a sum:  $ A^⊤+B^⊤=(A+B)^⊤ $ .**\n",
    "\n",
    "let $ C = A^T $\n",
    "\n",
    "let $ D = B^T $\n",
    "\n",
    "let $ E = A + B $\n",
    "\n",
    "let $ F = E^T $\n",
    "\n",
    "then $ c_{i, j} + d_{i, j} = a_{j, i} + b_{j, i} $\n",
    "\n",
    "and $ e_{i, j} = a_{i, j} + b_{i, j} $\n",
    "\n",
    "and $ f_{i, j} = e_{j, i} $\n",
    "\n",
    "so $ f_{i, j} = a_{j, i} + b_{j, i} = c{i, j} + d_{i, j} $\n",
    "\n",
    "and $ F = (A + B)^T = A^T + B^T$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Question 3 : Given any square matrix $ A $, is  $ A + A^⊤ $  always symmetric? Why?**\n",
    "\n",
    "by question 2 : $ (A + A ^ T)^T = A ^ T + A $\n",
    "\n",
    "$ A + B = B + A $ so $ A^T + A = A + A^T $ so $ A + A^T $ is always symetric"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Question 4 : We defined the tensor $ X $ of shape (2, 3, 4) in this section. What is the output of $ len(X) $?**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "len(X)"
   ]
  },
  {
   "source": [
    "**Question 5 : For a tensor $ X $ of arbitrary shape, does $ len(X) $ always correspond to the length of a certain axis of $ X $? What is that axis?**\n",
    "\n",
    "$ len(X) $ return the first dim of X"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Question 6 : Run $ A / A.sum(axis=1) $ and see what happens. Can you analyze the reason?**\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-69213997a7d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mA\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "A / A.sum(axis=1)"
   ]
  },
  {
   "source": [
    "The reason why it is not working is that $ A.sum(axis=1) $ is shape $ (5) $, because we sum over the first dimension and $ A $ is shape $ (5, 4) $. So on the divide operation $ (5) $ is broadcast to $ (1, 5) $ and like said at the end of [2.1_data_manipulaton.ipynb](vscode://file/E:/projects/my_answers_d2l/preliminaries/2.1_data_manipulation.ipynb), *** 'the dimensions to broadcast need to either be the same in both tensor, in all dimension or need to be one in not matching ones.'***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Question 7 : When traveling between two points in Manhattan, what is the distance that you need to cover in terms of the coordinates, i.e., in terms of avenues and streets? Can you travel diagonally?**\n",
    "\n",
    "The Manhattan distance between two vectors $ X $ of dim (x1, x2, …, xn) and $ Y $ of dim (y1, y2, …, yn) is the sum of the differences between each dimensions. You can't traverse diagonally."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Question 8 : Consider a tensor with shape (2, 3, 4). What are the shapes of the summation outputs along axis 0, 1 and 2 ?**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "X.sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "X.sum(axis=2).shape"
   ]
  },
  {
   "source": [
    "**Question 9 : Feed a tensor with $ 3 $ or more axes to the $ linalg.norm $ function and observe its output. What does this function compute for tensors of arbitrary shape ?**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(188.9974)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "Y = torch.arange(48, dtype=torch.float32).reshape(2, 3, 4, 2)\n",
    "torch.norm(Y)"
   ]
  },
  {
   "source": [
    "torch.norm compute the norm over all axis and return a float"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}